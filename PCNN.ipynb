{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656186f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from random import randint\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c58a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 6\n",
    "imageHeight = 256\n",
    "imageWidth = 256\n",
    "imageChannels = 3\n",
    "epochs = 30\n",
    "pp = 70000 # количество изображений, которые будут использоваться для обучения/тестирования\n",
    "pathM = 'data/masks'\n",
    "pathMT = 'data/masks_test'\n",
    "pathI = 'data/CelebA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab39d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# класс, создающий сеть с частичными свёртками и обучающий её\n",
    "class PCNN:\n",
    "    \n",
    "    # загрузка заданных слоёв предобученой модели vgg-16\n",
    "    def vgg16Layers(self, layerNames):\n",
    "        \n",
    "        vgg = VGG16(include_top=False, weights='imagenet')\n",
    "        vgg.trainable = False\n",
    "\n",
    "        outputs = [vgg.get_layer(name).output for name in layerNames]\n",
    "\n",
    "        model = tf.keras.Model([vgg.input], outputs)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    # вычисление матрицы Грама\n",
    "    def gramMatrix(self, inputTensor):\n",
    "        \n",
    "        result = tf.linalg.einsum('bijc,bijd->bcd', inputTensor, inputTensor)\n",
    "        inputShape = tf.shape(inputTensor)\n",
    "        numLocations = tf.cast(inputShape[1]*inputShape[2], tf.float32)\n",
    "        \n",
    "        return result/(numLocations)\n",
    "    \n",
    "    # функция потери L1\n",
    "    def L1(self, x):\n",
    "        \n",
    "        if len(x.get_shape()) == 4:\n",
    "            return tf.reduce_mean(tf.reduce_sum(tf.math.abs(x), [1, 2, 3]))\n",
    "        else: \n",
    "            return tf.reduce_mean(tf.reduce_sum(tf.math.abs(x), [1, 2]))\n",
    "    \n",
    "    # вычисление общей функции потерь\n",
    "    def lossFunction(self, mask, yTrue, yOut):\n",
    "    \n",
    "        lValid = self.L1(mask*(yOut-yTrue))\n",
    "        lHole = self.L1((1-mask)*(yOut-yTrue))\n",
    "        \n",
    "        \n",
    "        yСomp = (mask) * yTrue + (1-mask) * yOut\n",
    "        \n",
    "        compOut = self.vgg(yСomp)\n",
    "        trueOut = self.vgg(yTrue)\n",
    "        outOut = self.vgg(yOut)\n",
    "        \n",
    "        lPerceptual = 0\n",
    "        lStyleOut = 0\n",
    "        lStyleComp = 0\n",
    "        \n",
    "        for psiOut, psiComp, psiTrue in zip(outOut, compOut, trueOut):\n",
    "            \n",
    "            lPerceptual += self.L1(psiOut-psiTrue) + self.L1(psiComp-psiTrue)\n",
    "            \n",
    "            gramOut = self.gramMatrix(psiOut)\n",
    "            gramTrue = self.gramMatrix(psiTrue)\n",
    "            gramComp = self.gramMatrix(psiComp)\n",
    "            \n",
    "            lStyleOut += self.L1(gramOut-gramTrue)\n",
    "            lStyleComp += self.L1(gramComp-gramTrue)\n",
    "        \n",
    "        lTv = tf.reduce_mean(tf.image.total_variation(yСomp))\n",
    "        \n",
    "        lTotal = lValid + 6*lHole+0.05*lPerceptual+120*(lStyleOut+lStyleComp)+0.1*lTv\n",
    "        \n",
    "        return lTotal\n",
    "        \n",
    "    \n",
    "    def __init__(self, trainData, testData, epochs, batchSize, imageHeight = 227, imageWidth = 227, imageChannels = 3):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # ----- гиперпараметры обучения\n",
    "        self.epochs = epochs                   # количество эпох\n",
    "        self.batchSize = batchSize             # размер одного батча\n",
    "        self.imageHeight = imageHeight         # высота изображения\n",
    "        self.imageWidth = imageWidth           # ширина изображения\n",
    "        self.imageChannels = imageChannels     # количество каналов в изображении\n",
    "        \n",
    "        # ----- объекты и данные, используемые при обучении\n",
    "        \n",
    "        self.vgg = self.vgg16Layers(['block1_pool','block2_pool','block3_pool'])\n",
    "        \n",
    "        # данные для обучения\n",
    "        self.trainData = trainData\n",
    "        self.testData = testData\n",
    "        # исходное изображение\n",
    "        self.images =  tf.placeholder(tf.float32, [self.batchSize, self.imageHeight, self.imageWidth, self.imageChannels])\n",
    "        # исходное изображение с повреждённой областью внутри\n",
    "        self.damagedInputs = tf.placeholder(tf.float32, [self.batchSize, self.imageHeight, self.imageWidth, self.imageChannels])\n",
    "        # маска восстанавливаемой области\n",
    "        self.masks = tf.placeholder(tf.float32, [self.batchSize, self.imageHeight, self.imageWidth, self.imageChannels])\n",
    "        # генератор PCNN\n",
    "        generator = GEN(\"PCNN\")\n",
    "        \n",
    "        self.outputs = generator(self.damagedInputs, self.masks)\n",
    "        \n",
    "        self.loss = self.lossFunction(self.masks, self.images, self.outputs)\n",
    "        \n",
    "        self.genOptimizer = tf.train.AdamOptimizer(2e-4).minimize(self.loss, var_list=generator.get_var())\n",
    "        \n",
    "        self.costGen = tf.summary.scalar(\"Loss\", self.loss)\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.writerTest = tf.summary.FileWriter(\"./logs/test\")\n",
    "        self.writerTrain = tf.summary.FileWriter(\"./logs/train\")\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    # -------------------------------------------------------------- \n",
    "    # обучение\n",
    "    def train(self, i=0, whenSave = 1):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.writerTrain.add_graph(self.sess.graph)\n",
    "        self.writerTest.add_graph(self.sess.graph)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            im = []\n",
    "            im2 = []\n",
    "            \n",
    "            # ----- шаг обучения\n",
    "            for numberBatch in range(len(self.trainData)):\n",
    "                \n",
    "                originalImgs, damagedImgs, masks = self.trainData[numberBatch]\n",
    "                \n",
    "                self.sess.run(self.genOptimizer, feed_dict={self.images: originalImgs, self.damagedInputs: damagedImgs, self.masks: masks})\n",
    "            \n",
    "            # ----- вывод промежуточных результатов:\n",
    "            originalImgs2, damagedImgs2, masks2 = self.testData[0]\n",
    "\n",
    "            summaryTrain, resLossTrain = self.sess.run([self.merged, self.loss], feed_dict={self.images: originalImgs, self.damagedInputs: damagedImgs, self.masks: masks})\n",
    "\n",
    "            summaryTest, resLossTest = self.sess.run([self.merged, self.loss], feed_dict={self.images: originalImgs2, self.damagedInputs: damagedImgs2, self.masks: masks2})\n",
    "\n",
    "            self.writerTrain.add_summary(summaryTrain, i)\n",
    "            self.writerTest.add_summary(summaryTest, i)\n",
    "\n",
    "            print(\"Итерация \" + str(i) + \", loss = \" + str(resLossTrain) + \", loss Test = \" + str(resLossTest) + \".\")\n",
    "\n",
    "            # ----- сохраняем параметры нейросети каждые whenSave эпох\n",
    "            if (epoch + 1) % whenSave == 0:\n",
    "\n",
    "                resImage = self.sess.run([self.outputs], feed_dict={self.damagedInputs: damagedImgs2, self.masks: masks2})\n",
    "                \n",
    "                Image.fromarray(np.uint8(resImage[0][0]*255)).save(\"./Results//\" + str(i) + \".jpg\")\n",
    "                Image.fromarray(np.uint8(damagedImgs2[0]*255)).save(\"./Results//\" + str(i) + \"_1.jpg\")\n",
    "                self.saver.save(self.sess, \"./save_para//para.ckpt\")\n",
    "\n",
    "            self.trainData.on_epoch_end()\n",
    "            self.testData.on_epoch_end()\n",
    "            i=i+1\n",
    "\n",
    "    # -------------------------------------------------------------- \n",
    "    # восстановление данных\n",
    "    def restoreModel(self, pathMeta, path):\n",
    "\n",
    "        self.saver = tf.train.import_meta_graph(pathMeta)\n",
    "        self.saver.restore(self.sess, tf.train.latest_checkpoint(path))\n",
    "    \n",
    "    # -------------------------------------------------------------- \n",
    "    # использование готовой модели для восстановления изображения:\n",
    "    def useModel(self, image, mask):\n",
    "        \n",
    "        resImage = self.sess.run([self.outputs], feed_dict={self.damagedInputs: image, self.masks: mask})\n",
    "        Image.fromarray(np.uint8(resImage[0][0]*255)).save(\"./Results.jpg\")\n",
    "        print(\"Результат сохранен\")\n",
    "        \n",
    "    # -------------------------------------------------------------- \n",
    "    # использование готовой модели для восстановления изображения:\n",
    "    def useModel(self, image, mask):\n",
    "        \n",
    "        resImage = self.sess.run([self.outputs], feed_dict={self.damagedInputs: image, self.masks: mask})\n",
    "        Image.fromarray(np.uint8(resImage[0][0]*255)).save(\"./Results.jpg\")\n",
    "        print(\"Результат сохранен\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c6cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# реализация слоёв нейронной сети \n",
    "\n",
    "# ----- слой кодировщика\n",
    "def encoderLayers(name, inputs, masks, filters, kSize, batchNorm = True, biasUse = True):\n",
    "    \n",
    "    with tf.variable_scope(name + 'en'):\n",
    "    \n",
    "        outputsImgs, outputsMasks = pConv2D(name, inputs, masks, filters, kSize, stride=2, biasUse = biasUse)\n",
    "        \n",
    "        if biasUse:\n",
    "            b = tf.get_variable(\"b\",shape=[filters], initializer=tf.constant_initializer(0.))\n",
    "            outputsImgs = tf.nn.bias_add(outputsImgs, b)\n",
    "\n",
    "        outputsImgs = keras.layers.ReLU()(outputsImgs)\n",
    "\n",
    "        if batchNorm:\n",
    "            outputsImgs = tf.layers.batch_normalization(outputsImgs)\n",
    "    \n",
    "    return outputsImgs, outputsMasks\n",
    "\n",
    "# ----- слой декодировщика\n",
    "def decoderLayers(name, inputs, masks, concatIm, concatMask, filters, kSize, activationFunc = True, batchNorm = True, biasUse = True):\n",
    "    \n",
    "    with tf.variable_scope(name + 'de'):\n",
    "        \n",
    "        outputsImgs = upSampling(\"up\" + name, inputs, size=(2,2))\n",
    "        outputsMasks = upSampling(\"up\" + name + \"Masks\", masks, size=(2,2))\n",
    "\n",
    "        outputsImgs = keras.layers.concatenate(inputs = [concatIm, outputsImgs], axis=-1)\n",
    "        outputsMasks = keras.layers.concatenate(inputs=[concatMask, outputsMasks], axis=-1)\n",
    "\n",
    "        outputsImgs, outputsMasks = pConv2D(name, outputsImgs, outputsMasks, filters, kSize, stride=1, biasUse = biasUse)\n",
    "        \n",
    "        if biasUse:\n",
    "            b = tf.get_variable(\"b\",shape=[filters], initializer=tf.constant_initializer(0.))\n",
    "            outputsImgs = tf.nn.bias_add(outputsImgs, b)\n",
    "        \n",
    "        if activationFunc:\n",
    "            outputsImgs = keras.layers.LeakyReLU(0.2)(outputsImgs)\n",
    "\n",
    "        if batchNorm:\n",
    "            outputsImgs = tf.layers.batch_normalization(outputsImgs)\n",
    "    \n",
    "    return outputsImgs, outputsMasks\n",
    "\n",
    "\n",
    "# ----- частичная свёртка\n",
    "def pConv2D(name, inputs, masks, filters, kSize, stride, biasUse = True):\n",
    "    \n",
    "    \n",
    "    padding = [[0, 0],[int((kSize - 1) / 2), int((kSize - 1) / 2)],[int((kSize - 1) / 2), int((kSize - 1) / 2)],[0, 0]]\n",
    "\n",
    "    # дополняем маски и карты признаков нулями с помощью padding\n",
    "    pdMasks = tf.pad(masks, padding, \"CONSTANT\")\n",
    "    pdImages = tf.pad(inputs, padding, \"CONSTANT\")\n",
    "\n",
    "\n",
    "    outputImages = tf.layers.conv2d(inputs = pdImages*pdMasks,filters=filters,kernel_size=kSize,strides=stride,use_bias=False,name='features')\n",
    "\n",
    "    outputMasks = tf.layers.conv2d(inputs = pdMasks,filters=filters,kernel_size=kSize,strides=stride,kernel_initializer=tf.ones_initializer,use_bias=False,name='masks')\n",
    "\n",
    "    maskRatio = (kSize*kSize*inputs.shape._dims[3]._value) / (outputMasks + 1e-5)\n",
    "    outputMasks = tf.clip_by_value(outputMasks, 0.0, 1.0)\n",
    "    maskRatio = maskRatio*outputMasks\n",
    "    outputImages = maskRatio*outputImages\n",
    "        \n",
    "    return  outputImages, outputMasks\n",
    "\n",
    "\n",
    "# ----- повышающая дискритизация\n",
    "def upSampling(name, inputs, size):\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        outputImages = keras.layers.UpSampling2D(size=size)(inputs)\n",
    "        \n",
    "    return  outputImages\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# класс генератора\n",
    "class GEN:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, inputs, masks):\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            # ----- блок кодировщика\n",
    "            conv1, mask1 = encoderLayers('Pconv1', inputs, masks, filters = 64, kSize = 7, batchNorm = False)\n",
    "            conv2, mask2 = encoderLayers('Pconv2', conv1, mask1, filters = 128, kSize = 5)\n",
    "            conv3, mask3 = encoderLayers('Pconv3', conv2, mask2, filters = 256, kSize = 5)\n",
    "            conv4, mask4 = encoderLayers('Pconv4', conv3, mask3, filters = 512, kSize = 3)\n",
    "            conv5, mask5 = encoderLayers('Pconv5', conv4, mask4, filters = 512, kSize = 3)\n",
    "            conv6, mask6 = encoderLayers('Pconv6', conv5, mask5, filters = 512, kSize = 3)\n",
    "            conv7, mask7 = encoderLayers('Pconv7', conv6, mask6, filters = 512, kSize = 3)\n",
    "            # ----- блок декодировщика (decoder)\n",
    "            dconv1, dmask1 = decoderLayers('Pconv8', conv7, mask7, conv6, mask6, 512, kSize=3)\n",
    "            dconv2, dmask2 = decoderLayers('Pconv9', dconv1, dmask1, conv5, mask5, 512, kSize=3)\n",
    "            dconv3, dmask3 = decoderLayers('Pconv10', dconv2, dmask2, conv4, mask4, 512, kSize=3)\n",
    "            dconv4, dmask4 = decoderLayers('Pconv11', dconv3, dmask3, conv3, mask3, 256, kSize=3)\n",
    "            dconv5, dmask5 = decoderLayers('Pconv12', dconv4, dmask4, conv2, mask2, 128, kSize=3)\n",
    "            dconv6, dmask6 = decoderLayers('Pconv13', dconv5, dmask5, conv1, mask1, 64, kSize=3)\n",
    "            dconv7, dmask7 = decoderLayers('Pconv14', dconv6, dmask6, inputs, masks, 3, kSize=3, activationFunc = False, batchNorm = False)\n",
    "            \n",
    "            \n",
    "            return keras.layers.Activation('sigmoid')(dconv7)\n",
    "\n",
    "    def get_var(self):\n",
    "        return  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4482654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс, генерирующий тренировочные данные\n",
    "class createAugment():\n",
    "    \n",
    "    # --\n",
    "    # инициализация объекта класса\n",
    "    def __init__(self, imgs, masks, batch_size=10, dim=(128, 128), n_channels=3):\n",
    "        self.batch_size = batch_size  # размер батча\n",
    "        self.images = imgs            # исходное изображение\n",
    "        self.masks = masks            # маски изображений\n",
    "        self.dim = dim                # размер изображения\n",
    "        self.n_channels = n_channels  # количество каналов\n",
    "        self.on_epoch_end()           # генерация набора батчей\n",
    "    \n",
    "    # --\n",
    "    # результат: возможных батчей за эпоху\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.images) / self.batch_size))\n",
    "    \n",
    "    # --\n",
    "    # результат: взятие батча с заданным номером (индексом)\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        imageOrig, imageMasked, imageMasks = self.data_generation(indexes)\n",
    "        return imageOrig, imageMasked, imageMasks\n",
    "    \n",
    "    # --\n",
    "    # функция, повторяющаяся в конце каждой эпохи\n",
    "    # результат: новая совокупность индексов изображений для очередного батча\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.images))\n",
    "        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    # --\n",
    "    # результат: батч данных, включающий в себя \n",
    "    # маскированное изображение и часть изображения под маской\n",
    "    def data_generation(self, idxs):\n",
    "        \n",
    "        imageMasked = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # маскированное изображения\n",
    "        imageMasks = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # маски\n",
    "        imageOrig = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # изображение под маской\n",
    "\n",
    "        for i, idx in enumerate(idxs):\n",
    "            \n",
    "            image, masked_image, image_masks = self.createMask(self.images[idx].copy())\n",
    "            imageMasked[i,] = masked_image/255\n",
    "            imageOrig[i,] = image/255\n",
    "            imageMasks[i,] = image_masks/255\n",
    "            \n",
    "        return imageOrig, imageMasked, imageMasks\n",
    "    \n",
    "    # --\n",
    "    # поворот изображения\n",
    "    def imageRotate(self, img):\n",
    "        \n",
    "        angle = np.random.randint(1, 359)\n",
    "        M = cv2.getRotationMatrix2D((self.dim[0]//2, self.dim[1]//2), 45, 1.0)\n",
    "        rotated = cv2.warpAffine(img, M, self.dim)\n",
    "        \n",
    "        return rotated\n",
    "    \n",
    "    # --\n",
    "    # уменьшение изначальной маски\n",
    "    def imageResize(self, img):\n",
    "\n",
    "        background = np.full((self.dim[0], self.dim[1], self.n_channels), 0, np.uint8)\n",
    "\n",
    "        widthNew = np.random.randint(int(self.dim[0]/2), self.dim[0])\n",
    "        heightNew = np.random.randint(int(self.dim[1]/2), self.dim[1])\n",
    "        \n",
    "        imgNew = cv2.resize(img, (widthNew, heightNew))\n",
    "\n",
    "        xNew = np.random.randint(0, self.dim[0] - widthNew)\n",
    "        yNew = np.random.randint(0, self.dim[1] - heightNew)\n",
    "\n",
    "        background[yNew:yNew+heightNew,xNew:xNew+widthNew] = imgNew\n",
    "\n",
    "        return background\n",
    "    \n",
    "    # --\n",
    "    # добавляем дополнительные элементы\n",
    "    def imageDetails(self, mask):\n",
    "        \n",
    "        # генерируем количество линий-повреждений на рисунке\n",
    "        n_line = np.random.randint(1, 5)\n",
    "        \n",
    "        # рисуем линии\n",
    "        for i in range(n_line):\n",
    "            \n",
    "            # генерируем первую точку линии\n",
    "            x_start = np.random.randint(1, self.dim[0])\n",
    "            y_start = np.random.randint(1, self.dim[1])\n",
    "            \n",
    "            # генерируем вторую точку линии\n",
    "            x_finish = np.random.randint(1, self.dim[0])\n",
    "            y_finish = np.random.randint(1, self.dim[1])\n",
    "            \n",
    "            # определяем толщину линии\n",
    "            point = np.random.randint(1, 5)\n",
    "            \n",
    "            # рисуем линию между сгенерированными точками\n",
    "            cv2.line(mask, (x_start, y_start), (x_finish, y_finish), (255,255,255), point)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    # --\n",
    "    # маскированного изображения и изображения под маской\n",
    "    def createMask(self, image):\n",
    "        \n",
    "        randNumberOfMask = np.random.randint(0, len(self.masks)-1)\n",
    "        isRotate = np.random.randint(1, 10)\n",
    "        isResize = np.random.randint(1, 10)\n",
    "        \n",
    "        mask = (self.masks[randNumberOfMask].copy())\n",
    "        \n",
    "        if isResize%2 == 0:\n",
    "            mask = self.imageResize(mask)\n",
    "        \n",
    "        if isRotate%2 == 0:\n",
    "            mask = self.imageRotate(mask)\n",
    "          \n",
    "        \n",
    "        mask = self.imageDetails(mask)\n",
    "        \n",
    "        mask2 = (mask//255)*255\n",
    "        \n",
    "        imageMasked = cv2.bitwise_and(image, cv2.bitwise_not(mask2)) + mask2\n",
    "        \n",
    "        return image, imageMasked, cv2.bitwise_not(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c14925a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = os.listdir(pathI)\n",
    "masksPaths = os.listdir(pathM)\n",
    "masksPathsTest = os.listdir(pathMT)\n",
    "images = np.empty((pp, imageHeight, imageWidth, imageChannels), dtype='uint8')\n",
    "masks = np.empty((len(masksPaths), imageHeight, imageWidth, imageChannels), dtype='uint8')\n",
    "masksTest = np.empty((len(masksPathsTest), imageHeight, imageWidth, imageChannels), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71fa2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = imagePaths[20000+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f9e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for path in imagePaths:\n",
    "    img = Image.open(os.path.join(pathI, path))\n",
    "    img = img.resize((imageHeight,imageWidth))\n",
    "    images[i] = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    i = i+1\n",
    "    if i == pp:\n",
    "        break\n",
    "\n",
    "i = 0\n",
    "for path in masksPaths:\n",
    "    img = Image.open(os.path.join(pathM, path))\n",
    "    img = img.resize((imageHeight,imageWidth))\n",
    "    masks[i] = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    i = i+1  \n",
    "\n",
    "i = 0    \n",
    "for path in masksPathsTest:\n",
    "    img = Image.open(os.path.join(pathMT, path))\n",
    "    img = img.resize((imageHeight,imageWidth))\n",
    "    masksTest[i] = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    i = i+1\n",
    "    \n",
    "trainData = createAugment(images[0:int(pp*0.9)], masks, batchSize, dim = [imageHeight, imageWidth])\n",
    "testData = createAugment(images[int(pp*0.9):], masksTest, batchSize, dim = [imageHeight, imageWidth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3e79388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eneri\\anaconda3\\envs\\pleaseWork\\lib\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:536: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "C:\\Users\\Eneri\\anaconda3\\envs\\pleaseWork\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "C:\\Users\\Eneri\\anaconda3\\envs\\pleaseWork\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:423: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "network = PCNN(trainData, testData, epochs, batchSize, imageHeight, imageWidth, imageChannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9a60b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save_para\\para.ckpt\n"
     ]
    }
   ],
   "source": [
    "network.restoreModel('./save_para//para.ckpt.meta', './save_para')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19dc0f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация 271, loss = 22722.178, loss Test = 55206.68.\n",
      "Итерация 272, loss = 20647.96, loss Test = 24875.906.\n",
      "Итерация 273, loss = 26224.639, loss Test = 33998.242.\n",
      "Итерация 274, loss = 23789.27, loss Test = 27341.828.\n",
      "Итерация 275, loss = 23134.553, loss Test = 24035.438.\n",
      "Итерация 276, loss = 28417.535, loss Test = 32385.842.\n",
      "Итерация 277, loss = 19603.625, loss Test = 29634.87.\n",
      "Итерация 278, loss = 22776.908, loss Test = 29610.895.\n",
      "Итерация 279, loss = 21092.6, loss Test = 29431.51.\n",
      "Итерация 280, loss = 29746.922, loss Test = 26456.822.\n",
      "Итерация 281, loss = 18352.502, loss Test = 24031.531.\n",
      "Итерация 282, loss = 17888.988, loss Test = 31261.213.\n",
      "Итерация 283, loss = 20414.305, loss Test = 34811.94.\n",
      "Итерация 284, loss = 23413.12, loss Test = 28781.902.\n",
      "Итерация 285, loss = 24824.03, loss Test = 34467.27.\n",
      "Итерация 286, loss = 24320.703, loss Test = 21054.777.\n",
      "Итерация 287, loss = 16770.967, loss Test = 27517.303.\n",
      "Итерация 288, loss = 17982.83, loss Test = 31436.459.\n",
      "Итерация 289, loss = 22256.555, loss Test = 34489.812.\n",
      "Итерация 290, loss = 20349.588, loss Test = 47751.22.\n",
      "Итерация 291, loss = 25412.283, loss Test = 33549.16.\n",
      "Итерация 292, loss = 18290.543, loss Test = 21951.729.\n",
      "Итерация 293, loss = 29276.672, loss Test = 35122.902.\n",
      "Итерация 294, loss = 19437.62, loss Test = 30185.81.\n",
      "Итерация 295, loss = 20318.25, loss Test = 31407.8.\n",
      "Итерация 296, loss = 30754.48, loss Test = 24168.934.\n",
      "Итерация 297, loss = 29280.066, loss Test = 36410.223.\n",
      "Итерация 298, loss = 22640.13, loss Test = 30072.238.\n",
      "Итерация 299, loss = 19475.432, loss Test = 59951.777.\n",
      "Итерация 300, loss = 22084.521, loss Test = 39507.78.\n"
     ]
    }
   ],
   "source": [
    "network.train(271)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c160f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
